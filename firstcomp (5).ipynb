{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-11T14:18:28.291526Z","iopub.execute_input":"2022-04-11T14:18:28.292804Z","iopub.status.idle":"2022-04-11T14:18:28.305617Z","shell.execute_reply.started":"2022-04-11T14:18:28.292746Z","shell.execute_reply":"2022-04-11T14:18:28.304699Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"original_train = pd.read_csv(\"/kaggle/input/house-prices-advanced-regression-techniques/train.csv\")\noriginal_test = pd.read_csv(\"/kaggle/input/house-prices-advanced-regression-techniques/test.csv\")\n\n","metadata":{"execution":{"iopub.status.busy":"2022-04-11T14:18:28.820396Z","iopub.execute_input":"2022-04-11T14:18:28.821135Z","iopub.status.idle":"2022-04-11T14:18:28.869036Z","shell.execute_reply.started":"2022-04-11T14:18:28.821094Z","shell.execute_reply":"2022-04-11T14:18:28.868191Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"markdown","source":"Always work on a copy of the dataframe","metadata":{}},{"cell_type":"code","source":"train_copy = original_train.drop(['Id'],axis = 1).copy()\ntest_copy = original_test.drop(['Id'],axis = 1).copy()","metadata":{"execution":{"iopub.status.busy":"2022-04-11T14:18:29.351188Z","iopub.execute_input":"2022-04-11T14:18:29.351503Z","iopub.status.idle":"2022-04-11T14:18:29.364291Z","shell.execute_reply.started":"2022-04-11T14:18:29.351471Z","shell.execute_reply":"2022-04-11T14:18:29.363488Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"markdown","source":"# Drop columns with lots of null values","metadata":{}},{"cell_type":"code","source":"# calculatethe missing values in each feature\n#train_copy.isnull().sum()\n\n\n#Calculate the percentage of the missing values for each column\n#save the columns with percentages >= 40% in a list to drop them later\n\nnullColumns = [column for column in train_copy.columns if abs(train_copy[column].isnull().sum()/1460 * 100) >= 40]\n\n","metadata":{"execution":{"iopub.status.busy":"2022-04-11T14:18:29.401035Z","iopub.execute_input":"2022-04-11T14:18:29.401644Z","iopub.status.idle":"2022-04-11T14:18:29.434453Z","shell.execute_reply.started":"2022-04-11T14:18:29.401608Z","shell.execute_reply":"2022-04-11T14:18:29.433533Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"nullColumns","metadata":{"execution":{"iopub.status.busy":"2022-04-11T14:18:29.451881Z","iopub.execute_input":"2022-04-11T14:18:29.452200Z","iopub.status.idle":"2022-04-11T14:18:29.458640Z","shell.execute_reply.started":"2022-04-11T14:18:29.452163Z","shell.execute_reply":"2022-04-11T14:18:29.457427Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"# we drop the columns\ntrain_copy = train_copy.drop(columns = nullColumns,axis = 1)\ntest_copy= test_copy.drop(columns = nullColumns,axis = 1)","metadata":{"execution":{"iopub.status.busy":"2022-04-11T14:18:29.491076Z","iopub.execute_input":"2022-04-11T14:18:29.491438Z","iopub.status.idle":"2022-04-11T14:18:29.501438Z","shell.execute_reply.started":"2022-04-11T14:18:29.491405Z","shell.execute_reply":"2022-04-11T14:18:29.500053Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"markdown","source":"# Impute missing values\n","metadata":{}},{"cell_type":"code","source":"def impute(df):\n    \n    \"\"\"\n    This function imputes missing values for numeric and categorical datatypes\n    \"\"\"\n    for name in df.select_dtypes(include = (['int64','float64'])):\n        df[name] = df[name].fillna(0)\n    for name in df.select_dtypes(\"object\"):\n        df[name] = df[name].fillna(\"None\")\n    return df","metadata":{"execution":{"iopub.status.busy":"2022-04-11T14:18:29.520348Z","iopub.execute_input":"2022-04-11T14:18:29.520642Z","iopub.status.idle":"2022-04-11T14:18:29.528091Z","shell.execute_reply.started":"2022-04-11T14:18:29.520612Z","shell.execute_reply":"2022-04-11T14:18:29.527191Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"train_copy = impute(train_copy)\n","metadata":{"execution":{"iopub.status.busy":"2022-04-11T14:18:29.560758Z","iopub.execute_input":"2022-04-11T14:18:29.561419Z","iopub.status.idle":"2022-04-11T14:18:29.601719Z","shell.execute_reply.started":"2022-04-11T14:18:29.561364Z","shell.execute_reply":"2022-04-11T14:18:29.601013Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"test_copy = impute(test_copy)","metadata":{"execution":{"iopub.status.busy":"2022-04-11T14:18:29.620457Z","iopub.execute_input":"2022-04-11T14:18:29.621452Z","iopub.status.idle":"2022-04-11T14:18:29.660110Z","shell.execute_reply.started":"2022-04-11T14:18:29.621388Z","shell.execute_reply":"2022-04-11T14:18:29.659412Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"markdown","source":"# Establish a Baseline","metadata":{}},{"cell_type":"markdown","source":"Judge your feature engineering based on the score from the Baseline","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import mean_squared_log_error\nfrom sklearn.ensemble import GradientBoostingRegressor as XGBRegressor\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold, cross_val_score","metadata":{"execution":{"iopub.status.busy":"2022-04-11T14:18:29.730247Z","iopub.execute_input":"2022-04-11T14:18:29.730540Z","iopub.status.idle":"2022-04-11T14:18:29.735051Z","shell.execute_reply.started":"2022-04-11T14:18:29.730508Z","shell.execute_reply":"2022-04-11T14:18:29.734413Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"def score(df,y_transformed = False):\n\n    \"\"\"\n    a function that measures the RMSE with each feature egireeing step\n    \"\"\"\n    \n    # if null values exist in your dataset an error will be raised\n    # to make the function not vulnerable to nulls, always impute them:\n    \n    df = impute(df)\n    \n    X = df.copy()\n    y = X.pop(\"SalePrice\")\n    \n    # when we fix skewness of data later, we'll need to apply a log transform to the target variable(\"SalePrice\")\n    # so when we actually do the transform there is no need to do it again here\n    \n    if y_transformed == False:\n        log_y = np.log1p(y)\n    else:\n        log_y = y\n        \n    \n    for colname in X.select_dtypes([\"object\"]):\n        X[colname] = X[colname].astype('category')\n        X[colname] = X[colname].cat.codes\n    \n        \n    model =XGBRegressor()\n    \n    score = cross_val_score(\n        model, X, log_y, cv=5, scoring=\"neg_mean_squared_error\",\n    )\n    score = -1 * score.mean()\n    score = np.sqrt(score)\n    \n    print(\"Baseline score is : \",score)","metadata":{"execution":{"iopub.status.busy":"2022-04-11T14:18:29.790606Z","iopub.execute_input":"2022-04-11T14:18:29.791406Z","iopub.status.idle":"2022-04-11T14:18:29.800125Z","shell.execute_reply.started":"2022-04-11T14:18:29.791367Z","shell.execute_reply":"2022-04-11T14:18:29.799212Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"# show the value of the error\nscore(train_copy)\n\n","metadata":{"execution":{"iopub.status.busy":"2022-04-11T14:18:29.840580Z","iopub.execute_input":"2022-04-11T14:18:29.841387Z","iopub.status.idle":"2022-04-11T14:18:33.290077Z","shell.execute_reply.started":"2022-04-11T14:18:29.841349Z","shell.execute_reply":"2022-04-11T14:18:33.289438Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"markdown","source":"# Apply Pearson Correlation test for numeric variables","metadata":{}},{"cell_type":"code","source":"# # check the variance of the numerical features\n# # drop the columns with zero variance(zero variance means the column has only one value )\n\ntrain_copy.select_dtypes(include = ['int64','float64']).var()","metadata":{"execution":{"iopub.status.busy":"2022-04-11T14:18:33.291432Z","iopub.execute_input":"2022-04-11T14:18:33.292126Z","iopub.status.idle":"2022-04-11T14:18:33.304722Z","shell.execute_reply.started":"2022-04-11T14:18:33.292086Z","shell.execute_reply":"2022-04-11T14:18:33.303604Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"# plot the correlation matrix\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\ncorr = train_copy.corr()\nplt.figure(figsize=(25,25))\nsns.heatmap(corr, annot = True)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-11T14:18:33.305848Z","iopub.execute_input":"2022-04-11T14:18:33.306120Z","iopub.status.idle":"2022-04-11T14:18:39.737303Z","shell.execute_reply.started":"2022-04-11T14:18:33.306091Z","shell.execute_reply":"2022-04-11T14:18:39.736615Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"markdown","source":"# Check Multicollinearity","metadata":{}},{"cell_type":"code","source":"# this function creates a set of column names with multi-correlations \n\ndef correlation_calculate(dataframe):  #the threshold is normaly around 85%\n    correlated_features = set()\n    coor_matrix = dataframe.corr()\n    for x in range(len(coor_matrix.columns)):\n        for y in range(x):\n            if abs(coor_matrix.iloc[x,y]) > 0.7: # here the threshold is set to 70%\n                clname = coor_matrix.columns[x]\n                correlated_features.add(clname)\n            else:pass\n            \n    return correlated_features","metadata":{"execution":{"iopub.status.busy":"2022-04-11T14:18:39.738886Z","iopub.execute_input":"2022-04-11T14:18:39.739809Z","iopub.status.idle":"2022-04-11T14:18:39.746103Z","shell.execute_reply.started":"2022-04-11T14:18:39.739767Z","shell.execute_reply":"2022-04-11T14:18:39.745179Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"# the highly correlated columns names\n\ncorrelation_calculate(train_copy)","metadata":{"execution":{"iopub.status.busy":"2022-04-11T14:18:39.747513Z","iopub.execute_input":"2022-04-11T14:18:39.747754Z","iopub.status.idle":"2022-04-11T14:18:39.794803Z","shell.execute_reply.started":"2022-04-11T14:18:39.747725Z","shell.execute_reply":"2022-04-11T14:18:39.793951Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"# \"1stFlrSF\" is correlated with \"TotalBsmtSf\"  0.82\n\n# \"GarageArea\" is correlated with \"GarageCars\"  0.88\n\n# \"GarageYearBlt\" is correlated with \"YearBuilt\"  0.83\n\n# \"GrLivArea\" is correlated with \"TotRmsAbvGrd\"  0.83\n\n# drop \"TotalBsmtSf\" since it the \"1stFlrSF\" is handy\n\n# drop \"GarageArea\" since it is less correlated with the target\n\n# drop \"GarageYearBuilt\" since it is less correlated with the target\n\n# drop \"TotRmsAbvGrd\" since it is less correlated with the target\n\n","metadata":{"execution":{"iopub.status.busy":"2022-04-11T14:18:39.795961Z","iopub.execute_input":"2022-04-11T14:18:39.796195Z","iopub.status.idle":"2022-04-11T14:18:39.802850Z","shell.execute_reply.started":"2022-04-11T14:18:39.796169Z","shell.execute_reply":"2022-04-11T14:18:39.802194Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"markdown","source":"from each pair, we drop the column that is less correlated with the target,\nIf the correlation with the target is equal for both the columns, we rely on domain knowledge","metadata":{}},{"cell_type":"code","source":"# show the value of the error\n\nscore(train_copy.drop([\"TotalBsmtSF\",\"GarageArea\",\"TotRmsAbvGrd\"],axis = 1))\n\n","metadata":{"execution":{"iopub.status.busy":"2022-04-11T14:18:39.804317Z","iopub.execute_input":"2022-04-11T14:18:39.804662Z","iopub.status.idle":"2022-04-11T14:18:42.949921Z","shell.execute_reply.started":"2022-04-11T14:18:39.804532Z","shell.execute_reply":"2022-04-11T14:18:42.948950Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"markdown","source":"notice that dropping the correlated columns barely decreased the error( or didn't make a change), so we fix Multicollinearity later using regularization\n","metadata":{}},{"cell_type":"markdown","source":"# apply Chi-square test and V-Cramer's test for the categorical features","metadata":{}},{"cell_type":"code","source":"# ordinal_features = ['LotShape','LandContour','LandSlope','ExterQual','ExterCond','BsmtQual','BsmtCond','BsmtExposure','BsmtFinType1','BsmtFinType2','HeatingQC','KitchenQual','GarageFinish','GarageQual','GarageCond']\n# nominal_features = [column for column in train_copy.columns if column not in ordinal_features and train_copy[column].dtypes=='object']","metadata":{"execution":{"iopub.status.busy":"2022-04-11T14:18:42.951252Z","iopub.execute_input":"2022-04-11T14:18:42.951501Z","iopub.status.idle":"2022-04-11T14:18:42.955950Z","shell.execute_reply.started":"2022-04-11T14:18:42.951470Z","shell.execute_reply":"2022-04-11T14:18:42.955104Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"import scipy.stats as stats\n\n# if you use a data frame with null values, it will raise an error\n\ndef chi_square_test(dataframe):\n    \n    \"\"\"\n    this function calculates the Cramer's V-test for categorical variables \n    if there is a dependence between them\n        \"\"\"\n    # loop through the categorical columns\n    \n    for column1 in dataframe.select_dtypes('object'):\n        for column2 in dataframe.select_dtypes('object'):\n            \n            # create a contingency table between every two features\n            \n            myCrosstable = pd.crosstab(index = dataframe[column1],columns = dataframe[column2])\n            \n            # calculate the chi-square value,the p-value, the degrees of freedom and the expected values:\n            \n            (chiVal, pVal, df, exp) = stats.chi2_contingency(myCrosstable)\n            \n            # only proceed with the test if the distribution is significant\n            \n            if pVal <0.05:\n                \n                # now we check if the results are reliable:\n                # 1- the least expected value should be 1\n                # 2- only 20% of the cells are allowed to have a value below 5\n                \n                if (exp.min() >=1) and ((len(exp[exp<5])/len(exp) *100) <=20):\n                    n = np.sum(np.array(myCrosstable))\n                    minDim = min(myCrosstable.shape)-1\n                    association_strength = np.sqrt((chiVal/n)/(minDim))\n                    print(\"The association strength between {myField1} and {myField2} is : \".format(myField1 = column1, myField2 = column2),association_strength)\n                else:pass\n            else:pass\n                \n\nchi_square_test(train_copy)","metadata":{"execution":{"iopub.status.busy":"2022-04-11T14:18:42.957521Z","iopub.execute_input":"2022-04-11T14:18:42.957770Z","iopub.status.idle":"2022-04-11T14:18:58.995268Z","shell.execute_reply.started":"2022-04-11T14:18:42.957732Z","shell.execute_reply":"2022-04-11T14:18:58.994233Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"# a value between( 0.4 to 1.00) for the V-cramer's test indicates a strong association\n# we drop either one of two columns which have an association strength between 0.4-1.00 or apply some transformation on the features\n# as you notice, no strong associations are present between the columns\n","metadata":{"execution":{"iopub.status.busy":"2022-04-11T14:18:58.999610Z","iopub.execute_input":"2022-04-11T14:18:58.999939Z","iopub.status.idle":"2022-04-11T14:18:59.003830Z","shell.execute_reply.started":"2022-04-11T14:18:58.999906Z","shell.execute_reply":"2022-04-11T14:18:59.002653Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"markdown","source":"# Now we perform the Mutual Information utility metric for feature selection","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_selection import mutual_info_regression\n","metadata":{"execution":{"iopub.status.busy":"2022-04-11T14:18:59.005466Z","iopub.execute_input":"2022-04-11T14:18:59.005799Z","iopub.status.idle":"2022-04-11T14:18:59.030299Z","shell.execute_reply.started":"2022-04-11T14:18:59.005757Z","shell.execute_reply":"2022-04-11T14:18:59.029201Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"\ndef mutual_info_calculator(df):\n    \"\"\"\n    calculate the mutual information between each feature and  the target variable\n    \"\"\"\n    \n    X = df.copy() \n    for colname in X.select_dtypes(\"object\"):\n        X[colname], _ = X[colname].factorize()\n        \n    # or: \n\n    # for colname in XX.select_dtypes(\"object\"):\n    #     col, index= XX[colname].factorize()\n    #     XX[colname] = col\n        \n        \n    discrete_features = X.dtypes == int\n    \n    mi_scores = mutual_info_regression(X, X['SalePrice'], discrete_features=discrete_features)\n    mi_scores = pd.Series(mi_scores, name=\"MI Scores\", index=X.columns)\n    mi_scores = mi_scores.sort_values(ascending=True)\n   \n    for i in range(len(mi_scores)) :\n        print(mi_scores.index[i],mi_scores[i])","metadata":{"execution":{"iopub.status.busy":"2022-04-11T14:18:59.033081Z","iopub.execute_input":"2022-04-11T14:18:59.033422Z","iopub.status.idle":"2022-04-11T14:18:59.041058Z","shell.execute_reply.started":"2022-04-11T14:18:59.033388Z","shell.execute_reply":"2022-04-11T14:18:59.040163Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"mutual_info_calculator(train_copy)","metadata":{"execution":{"iopub.status.busy":"2022-04-11T14:18:59.042298Z","iopub.execute_input":"2022-04-11T14:18:59.042720Z","iopub.status.idle":"2022-04-11T14:19:02.129573Z","shell.execute_reply.started":"2022-04-11T14:18:59.042689Z","shell.execute_reply":"2022-04-11T14:19:02.126155Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"#Columns with mutual info value equal or very close to zero indicates full independence, \n#which mean they have zero effect on the target variable and thus are uninformative for us, so we drop them\n\ntrain_copy.drop(columns = ['Utilities','MiscVal','MoSold','Street','YrSold','PoolArea'],inplace = True)","metadata":{"execution":{"iopub.status.busy":"2022-04-11T14:19:02.133237Z","iopub.execute_input":"2022-04-11T14:19:02.133482Z","iopub.status.idle":"2022-04-11T14:19:02.139708Z","shell.execute_reply.started":"2022-04-11T14:19:02.133454Z","shell.execute_reply":"2022-04-11T14:19:02.138928Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"test_copy.drop(columns = ['Utilities','MiscVal','MoSold','Street','YrSold','PoolArea'],inplace = True)","metadata":{"execution":{"iopub.status.busy":"2022-04-11T14:19:02.140811Z","iopub.execute_input":"2022-04-11T14:19:02.141219Z","iopub.status.idle":"2022-04-11T14:19:02.155574Z","shell.execute_reply.started":"2022-04-11T14:19:02.141187Z","shell.execute_reply":"2022-04-11T14:19:02.154576Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"# now check the score\nscore(train_copy)","metadata":{"execution":{"iopub.status.busy":"2022-04-11T14:19:02.158111Z","iopub.execute_input":"2022-04-11T14:19:02.159010Z","iopub.status.idle":"2022-04-11T14:19:05.521447Z","shell.execute_reply.started":"2022-04-11T14:19:02.158964Z","shell.execute_reply":"2022-04-11T14:19:05.520570Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"markdown","source":"# Check for data normality","metadata":{}},{"cell_type":"code","source":"import seaborn as sns\n","metadata":{"execution":{"iopub.status.busy":"2022-04-11T14:19:05.522835Z","iopub.execute_input":"2022-04-11T14:19:05.524328Z","iopub.status.idle":"2022-04-11T14:19:05.528608Z","shell.execute_reply.started":"2022-04-11T14:19:05.524278Z","shell.execute_reply":"2022-04-11T14:19:05.528014Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"# Plot a histogram of the target variable to check whether it is normally distributed or not\n\nsns.distplot(train_copy['SalePrice']);\n# or use : sns.displot(train_copy['SalePrice']); or sns.histplot(train_copy['SalePrice']);\n","metadata":{"execution":{"iopub.status.busy":"2022-04-11T14:19:05.529743Z","iopub.execute_input":"2022-04-11T14:19:05.530687Z","iopub.status.idle":"2022-04-11T14:19:05.902112Z","shell.execute_reply.started":"2022-04-11T14:19:05.530630Z","shell.execute_reply":"2022-04-11T14:19:05.901182Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"markdown","source":"notice that the target variable is positively skewed","metadata":{}},{"cell_type":"code","source":"# Now we check the skewness of other features\n\ntrain_copy.select_dtypes(include = ['int64','float64']).skew()","metadata":{"execution":{"iopub.status.busy":"2022-04-11T14:19:05.903394Z","iopub.execute_input":"2022-04-11T14:19:05.903636Z","iopub.status.idle":"2022-04-11T14:19:05.916669Z","shell.execute_reply.started":"2022-04-11T14:19:05.903609Z","shell.execute_reply":"2022-04-11T14:19:05.915557Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"markdown","source":"# Fix data skewness","metadata":{}},{"cell_type":"code","source":"## Import necessary modules \n\nfrom scipy.special import boxcox1p\nfrom scipy.stats import boxcox_normmax","metadata":{"execution":{"iopub.status.busy":"2022-04-11T14:19:05.918282Z","iopub.execute_input":"2022-04-11T14:19:05.918683Z","iopub.status.idle":"2022-04-11T14:19:05.924839Z","shell.execute_reply.started":"2022-04-11T14:19:05.918638Z","shell.execute_reply":"2022-04-11T14:19:05.923935Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"code","source":"#the `MSSubClass` feature is read as an `int` type, but is actually a (nominative) categorical\n\nedit_feature = {\"MSSubClass\": {20:'1-STORY 1946 & NEWER ALL STYLES'\n                             ,30:'1-STORY 1945 & OLDER'\n                             ,40:'1-STORY W/FINISHED ATTIC ALL AGES'\n                             ,45:'1-1/2 STORY - UNFINISHED ALL AGES'\n                             ,50:'1-1/2 STORY FINISHED ALL AGES'\n                             ,60:'2-STORY 1946 & NEWER'\n                             ,70:'2-STORY 1945 & OLDER'\n                             ,75:'2-1/2 STORY ALL AGES'\n                             ,80:'SPLIT OR MULTI-LEVEL'\n                             ,85:'SPLIT FOYER'\n                             ,90:'DUPLEX - ALL STYLES AND AGES'\n                             ,120:'1-STORY PUD (Planned Unit Development) - 1946 & NEWER'\n                             ,150:'1-1/2 STORY PUD - ALL AGES'\n                             ,160:'2-STORY PUD - 1946 & NEWER'\n                             ,180:'PUD - MULTILEVEL - INCL SPLIT LEV/FOYER'\n                             ,190:'2 FAMILY CONVERSION - ALL STYLES AND AGES'}}\n              \ntrain_copy = train_copy.replace(edit_feature)\ntest_copy = test_copy.replace(edit_feature)\n\n","metadata":{"execution":{"iopub.status.busy":"2022-04-11T14:19:05.926639Z","iopub.execute_input":"2022-04-11T14:19:05.926938Z","iopub.status.idle":"2022-04-11T14:19:05.944488Z","shell.execute_reply.started":"2022-04-11T14:19:05.926909Z","shell.execute_reply":"2022-04-11T14:19:05.943512Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"code","source":"def view_skew(dataframe):\n    \"\"\"\n    this function determies which transformation is better\n    by comparing the value of skew for each variable after each transformation\n\n    \"\"\"\n    skewed_features = [column for column in dataframe.select_dtypes(include = ['int64','float64'])]\n    log = 0\n    squareroot = 0\n    recprocal = 0\n    exponential = 0\n    \n    log_cols = []\n    squareroot_cols = []\n    recprocal_cols = []\n    exponential_cols = []\n    \n    for column in skewed_features:\n        \n        log_transform = abs(np.log1p(dataframe[column]).skew())\n        SquareRoot_transform = abs(np.sqrt(dataframe[column]).skew())\n        reciprocal_transform = abs((1/(dataframe[column]+1)).skew())\n        exponential_transform = abs((dataframe[column]**(1/5)).skew())\n        \n        transforms = {'log':log_transform,\n                      'squareroot':SquareRoot_transform,\n                      'recprocal':reciprocal_transform,\n                      'exponential':exponential_transform}\n        \n        \n        best_score =[log_transform]\n        the_transform = ['log']\n        \n        for key,element in transforms.items():\n            \n            if element <best_score[0]:\n                best_score = [element]\n                the_transform = [key]\n            else:pass\n        if the_transform[0] == 'log':\n            log+=1\n            log_cols.append(column)\n            \n        elif the_transform[0] == 'squareroot':\n            squareroot+=1\n            squareroot_cols.append(column)\n            \n        elif the_transform[0] == 'recprocal':\n            recprocal+=1\n            recprocal_cols.append(column)\n            \n        else:\n            exponential+=1\n            exponential_cols.append(column)\n            \n           # uncomment the following line to view the result of each individual feature:\n#         print('the best transform for : ',column,'is',the_transform, \"it's score is :\",best_score)\n    \n    # print the count of features that each transform minimzed its skew\n    print('count of features where log performed better :',log)\n    print('count of features where square root performed better :',squareroot)\n    print('count of features where reciprocal performed better :',recprocal)\n    print('count of features where exponential performed better :',exponential)\n    \n    return  log_cols, squareroot_cols, recprocal_cols, exponential_cols","metadata":{"execution":{"iopub.status.busy":"2022-04-11T14:19:05.945582Z","iopub.execute_input":"2022-04-11T14:19:05.945808Z","iopub.status.idle":"2022-04-11T14:19:05.961053Z","shell.execute_reply.started":"2022-04-11T14:19:05.945780Z","shell.execute_reply":"2022-04-11T14:19:05.960119Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"code","source":"log_cols, squareroot_cols, recprocal_cols, exponential_cols = view_skew(train_copy.copy())","metadata":{"execution":{"iopub.status.busy":"2022-04-11T14:19:05.962231Z","iopub.execute_input":"2022-04-11T14:19:05.962627Z","iopub.status.idle":"2022-04-11T14:19:06.027726Z","shell.execute_reply.started":"2022-04-11T14:19:05.962598Z","shell.execute_reply":"2022-04-11T14:19:06.025965Z"},"trusted":true},"execution_count":68,"outputs":[]},{"cell_type":"code","source":"def transform(df,features,transform ):\n    \n    \"\"\"\n    This function applies the appropriate transform for each feature in order to fix skew\n    \"\"\"\n    if transform == 'sqrt':\n        df[features] = np.sqrt(df[features])\n        \n    elif transform =='log':\n        df[features] = np.log1p(df[features])\n        \n    elif transform =='expo':\n        df[features] = df[features]**(1/5)\n        \n    else:\n        df[features] = 1/(df[features]+1)\n    \n    return df","metadata":{"execution":{"iopub.status.busy":"2022-04-11T14:19:06.029529Z","iopub.execute_input":"2022-04-11T14:19:06.029923Z","iopub.status.idle":"2022-04-11T14:19:06.038711Z","shell.execute_reply.started":"2022-04-11T14:19:06.029875Z","shell.execute_reply":"2022-04-11T14:19:06.037708Z"},"trusted":true},"execution_count":69,"outputs":[]},{"cell_type":"code","source":"train_copy = transform(train_copy,log_cols,'log')\ntrain_copy = transform(train_copy,squareroot_cols,'sqrt')\ntrain_copy = transform(train_copy,recprocal_cols,'recipro')\ntrain_copy = transform(train_copy,exponential_cols,'expo')","metadata":{"execution":{"iopub.status.busy":"2022-04-11T14:19:06.040005Z","iopub.execute_input":"2022-04-11T14:19:06.040278Z","iopub.status.idle":"2022-04-11T14:19:06.073704Z","shell.execute_reply.started":"2022-04-11T14:19:06.040246Z","shell.execute_reply":"2022-04-11T14:19:06.072596Z"},"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"code","source":"test_copy =  transform(test_copy,exponential_cols,'expo')\nlog_cols = ['LotArea','1stFlrSF','GrLivArea','FullBath','BedroomAbvGr','GarageCars','OpenPorchSF']\ntest_copy = transform(test_copy,log_cols,'log')\ntest_copy = transform(test_copy,squareroot_cols,'sqrt')\ntest_copy = transform(test_copy,recprocal_cols,'recipro')","metadata":{"execution":{"iopub.status.busy":"2022-04-11T14:19:06.075119Z","iopub.execute_input":"2022-04-11T14:19:06.075404Z","iopub.status.idle":"2022-04-11T14:19:06.097689Z","shell.execute_reply.started":"2022-04-11T14:19:06.075375Z","shell.execute_reply":"2022-04-11T14:19:06.096679Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"code","source":"# check the score\nscore(train_copy,True)","metadata":{"execution":{"iopub.status.busy":"2022-04-11T14:19:06.099249Z","iopub.execute_input":"2022-04-11T14:19:06.099810Z","iopub.status.idle":"2022-04-11T14:19:09.400217Z","shell.execute_reply.started":"2022-04-11T14:19:06.099765Z","shell.execute_reply":"2022-04-11T14:19:09.399334Z"},"trusted":true},"execution_count":72,"outputs":[]},{"cell_type":"markdown","source":"# Create features with Principal Component Analysis","metadata":{}},{"cell_type":"code","source":"# first we take the highest MI scoring numeric features\nfeatures = ['GarageCars','LotArea','TotalBsmtSF','YearBuilt','GrLivArea' ,'GarageArea']","metadata":{"execution":{"iopub.status.busy":"2022-04-11T14:19:09.405155Z","iopub.execute_input":"2022-04-11T14:19:09.405414Z","iopub.status.idle":"2022-04-11T14:19:09.409611Z","shell.execute_reply.started":"2022-04-11T14:19:09.405385Z","shell.execute_reply":"2022-04-11T14:19:09.408645Z"},"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"code","source":"from sklearn.decomposition import PCA\n","metadata":{"execution":{"iopub.status.busy":"2022-04-11T14:19:09.410997Z","iopub.execute_input":"2022-04-11T14:19:09.411240Z","iopub.status.idle":"2022-04-11T14:19:09.423737Z","shell.execute_reply.started":"2022-04-11T14:19:09.411212Z","shell.execute_reply":"2022-04-11T14:19:09.422833Z"},"trusted":true},"execution_count":74,"outputs":[]},{"cell_type":"code","source":"def create_PC(df,features,standarize = True):\n    \"\"\"\n    This function creates principle component features from variations in original features\n    \"\"\"\n\n    X = df.loc[:, features]\n\n    # Standardize\n    if standarize:\n        X_scaled = (X - X.mean(axis=0)) / X.std(axis=0)\n    \n    # Create principal components\n    pca = PCA()\n    X_pca = pca.fit_transform(X_scaled)\n\n    # Convert to dataframe\n    component_names = [f\"PC{i+1}\" for i in range(X_pca.shape[1])]\n    X_pca = pd.DataFrame(X_pca, columns=component_names)\n    \n    # Create loadings\n    loadings = pd.DataFrame(\n    pca.components_.T,  # transpose the matrix of loadings\n    columns=component_names,  # so the columns are the principal components\n    index=X.columns,  # and the rows are the original features\n    )\n    return X_pca, loadings\n    ","metadata":{"execution":{"iopub.status.busy":"2022-04-11T14:19:09.425305Z","iopub.execute_input":"2022-04-11T14:19:09.425601Z","iopub.status.idle":"2022-04-11T14:19:09.437304Z","shell.execute_reply.started":"2022-04-11T14:19:09.425571Z","shell.execute_reply":"2022-04-11T14:19:09.436294Z"},"trusted":true},"execution_count":75,"outputs":[]},{"cell_type":"code","source":"X_pca, loadings = create_PC(train_copy,features)","metadata":{"execution":{"iopub.status.busy":"2022-04-11T14:19:09.438954Z","iopub.execute_input":"2022-04-11T14:19:09.439289Z","iopub.status.idle":"2022-04-11T14:19:09.466854Z","shell.execute_reply.started":"2022-04-11T14:19:09.439250Z","shell.execute_reply":"2022-04-11T14:19:09.465999Z"},"trusted":true},"execution_count":76,"outputs":[]},{"cell_type":"code","source":"X_pca","metadata":{"execution":{"iopub.status.busy":"2022-04-11T14:19:09.468347Z","iopub.execute_input":"2022-04-11T14:19:09.468881Z","iopub.status.idle":"2022-04-11T14:19:09.495520Z","shell.execute_reply.started":"2022-04-11T14:19:09.468848Z","shell.execute_reply":"2022-04-11T14:19:09.494582Z"},"trusted":true},"execution_count":77,"outputs":[]},{"cell_type":"code","source":"loadings","metadata":{"execution":{"iopub.status.busy":"2022-04-11T14:19:09.497063Z","iopub.execute_input":"2022-04-11T14:19:09.497326Z","iopub.status.idle":"2022-04-11T14:19:09.513812Z","shell.execute_reply.started":"2022-04-11T14:19:09.497297Z","shell.execute_reply":"2022-04-11T14:19:09.513120Z"},"trusted":true},"execution_count":78,"outputs":[]},{"cell_type":"markdown","source":"From the first principal component (PC1), notice that it describes some kind of an 'overall size' feature where all the features have a positive sign, and particularly the garage capacity in car is positively related to the garage area\n\nThe second principal component (PC2), indicates a contrast in the garage area between properties having a large above ground finished area and large lot area in comparison with properties having relatively small total finished basement area and built earlier \n\nI'm gonna ignore the other remaining four principle components since they have near zero values and doesn't show any clear variation","metadata":{}},{"cell_type":"code","source":"# now we add the new features\n\n#inspired by loadings(CP1):\ntrain_copy['PCA_feature'] = (train_copy.GarageCars)*(train_copy.GarageArea)\n\n# use components\ntrain_copy = train_copy.join(X_pca)","metadata":{"execution":{"iopub.status.busy":"2022-04-11T14:19:09.514944Z","iopub.execute_input":"2022-04-11T14:19:09.515228Z","iopub.status.idle":"2022-04-11T14:19:09.528861Z","shell.execute_reply.started":"2022-04-11T14:19:09.515198Z","shell.execute_reply":"2022-04-11T14:19:09.527699Z"},"trusted":true},"execution_count":79,"outputs":[]},{"cell_type":"code","source":"X_pca, loadings = create_PC(test_copy,features)\ntest_copy['PCA_feature'] = (test_copy.GarageCars)*(test_copy.GarageArea)\n\n# use components\ntest_copy = test_copy.join(X_pca)","metadata":{"execution":{"iopub.status.busy":"2022-04-11T14:19:09.530461Z","iopub.execute_input":"2022-04-11T14:19:09.530908Z","iopub.status.idle":"2022-04-11T14:19:09.549598Z","shell.execute_reply.started":"2022-04-11T14:19:09.530825Z","shell.execute_reply":"2022-04-11T14:19:09.548877Z"},"trusted":true},"execution_count":80,"outputs":[]},{"cell_type":"code","source":"score(train_copy,True)","metadata":{"execution":{"iopub.status.busy":"2022-04-11T14:19:09.551031Z","iopub.execute_input":"2022-04-11T14:19:09.551669Z","iopub.status.idle":"2022-04-11T14:19:14.068401Z","shell.execute_reply.started":"2022-04-11T14:19:09.551623Z","shell.execute_reply":"2022-04-11T14:19:14.067443Z"},"trusted":true},"execution_count":81,"outputs":[]},{"cell_type":"markdown","source":"# Now we encode the categorical features","metadata":{}},{"cell_type":"code","source":"# recall that we dropped the following columns:\n\n# ['Alley', 'FireplaceQu', 'PoolQC', 'Fence', 'MiscFeature',\n#'Utilities','MiscVal','MoSold','Street','YrSold','PoolArea']\n","metadata":{"execution":{"iopub.status.busy":"2022-04-11T14:19:14.069870Z","iopub.execute_input":"2022-04-11T14:19:14.070204Z","iopub.status.idle":"2022-04-11T14:19:14.074708Z","shell.execute_reply.started":"2022-04-11T14:19:14.070161Z","shell.execute_reply":"2022-04-11T14:19:14.073835Z"},"trusted":true},"execution_count":82,"outputs":[]},{"cell_type":"code","source":"# Now we take a  look at the dataset and decide which features to be nominally or ordinally encoded\n\nnominal_features = [ \"MSSubClass\",\"MSZoning\", \"LotConfig\",\n                \"Neighborhood\", \"Condition1\", \"Condition2\", \"BldgType\", \"HouseStyle\",\n                \"RoofStyle\", \"RoofMatl\", \"Exterior1st\", \"Exterior2nd\", \"MasVnrType\", \n                \"Foundation\", \"Heating\", \"CentralAir\", \"GarageType\", \"SaleType\", \"SaleCondition\",\"Functional\"]\n\nordinal_features = [column for column in train_copy.select_dtypes(include= ['object']).columns if column not in nominal_features ]","metadata":{"execution":{"iopub.status.busy":"2022-04-11T14:19:14.076318Z","iopub.execute_input":"2022-04-11T14:19:14.077132Z","iopub.status.idle":"2022-04-11T14:19:14.093412Z","shell.execute_reply.started":"2022-04-11T14:19:14.077082Z","shell.execute_reply":"2022-04-11T14:19:14.092534Z"},"trusted":true},"execution_count":83,"outputs":[]},{"cell_type":"code","source":"#Now before ordinal encoding, we create a list of lists containing the unique values in each cat feature\nfor i in ordinal_features: \n    print(i,train_copy[i].unique())\n    ","metadata":{"execution":{"iopub.status.busy":"2022-04-11T14:19:14.095089Z","iopub.execute_input":"2022-04-11T14:19:14.095766Z","iopub.status.idle":"2022-04-11T14:19:14.127030Z","shell.execute_reply.started":"2022-04-11T14:19:14.095719Z","shell.execute_reply":"2022-04-11T14:19:14.126382Z"},"trusted":true},"execution_count":84,"outputs":[]},{"cell_type":"markdown","source":"### ordinal encoding","metadata":{}},{"cell_type":"code","source":"categories = {'LotShape': {'Reg':4 ,'IR1':3, 'IR2':2 ,'IR3':1,'None':0},\n              'LandContour':{'Lvl':4, 'Bnk':3, 'HLS':2,'Low':1,'None':0},\n              'LandSlope':{'Gtl':3 ,'Mod':2, 'Sev':1,'None':0},\n              'ExterQual':{'Ex':5,'Gd':4 ,'TA' :3,'Fa':2,'Po':1,'None':0},\n              'ExterCond':{'Ex':5,'Gd':4 ,'TA' :3,'Fa':2,'Po':1,'None':0},\n              'BsmtQual':{'Ex':5,'Gd':4 ,'TA' :3,'Fa':2,'Po':1,'None':0},\n              'BsmtCond':{'Ex':5,'Gd':4 ,'TA' :3,'Fa':2,'Po':1,'None':0 },\n              'BsmtExposure':{'Gd':4,'Av':3,'Mn':2,'No':1,'None':0 }                      ,\n              'BsmtFinType1':{'GLQ':6, 'ALQ':5,'BLQ':4,'Rec':3, 'LwQ':2 , 'Unf':1,'None':0},\n              'BsmtFinType2':{'GLQ':6, 'ALQ':5,'BLQ':4,'Rec':3, 'LwQ':2 , 'Unf':1,'None':0},\n              'HeatingQC':{'Ex':5,'Gd':4 ,'TA' :3,'Fa':2,'Po':1,'None':0},\n              'KitchenQual':{'Ex':5,'Gd':4 ,'TA' :3,'Fa':2,'Po':1,'None':0},\n              'GarageQual':{'Ex':5,'Gd':4 ,'TA' :3,'Fa':2,'Po':1,'None':0},\n              'GarageCond':{'Ex':5,'Gd':4 ,'TA' :3,'Fa':2,'Po':1,'None':0},\n              'PavedDrive':{'Y':3,'P':2,'N':1,'None':0},\n              'Electrical':{'SBrkr':5,'FuseA':4,'FuseF':3,'FuseP':2,'Mix':1,'None':0},\n              'GarageFinish':{'RFn':3, 'Unf':2 ,'Fin':1, 'None':0}}\n\n\ndef ordinal_encode(df):\n    \"\"\"\n    this function encodes ordinal categorical features\n    \"\"\"\n    df = df.replace(categories)\n    return df","metadata":{"execution":{"iopub.status.busy":"2022-04-11T14:19:14.128079Z","iopub.execute_input":"2022-04-11T14:19:14.128657Z","iopub.status.idle":"2022-04-11T14:19:14.144808Z","shell.execute_reply.started":"2022-04-11T14:19:14.128623Z","shell.execute_reply":"2022-04-11T14:19:14.144152Z"},"trusted":true},"execution_count":85,"outputs":[]},{"cell_type":"code","source":"train_copy = ordinal_encode(train_copy)\ntest_copy = ordinal_encode(test_copy)","metadata":{"execution":{"iopub.status.busy":"2022-04-11T14:19:14.145925Z","iopub.execute_input":"2022-04-11T14:19:14.146624Z","iopub.status.idle":"2022-04-11T14:19:14.264734Z","shell.execute_reply.started":"2022-04-11T14:19:14.146571Z","shell.execute_reply":"2022-04-11T14:19:14.263631Z"},"trusted":true},"execution_count":86,"outputs":[]},{"cell_type":"markdown","source":"### nominal encoding","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder\nohe = OneHotEncoder(handle_unknown = 'ignore')","metadata":{"execution":{"iopub.status.busy":"2022-04-11T14:19:14.267071Z","iopub.execute_input":"2022-04-11T14:19:14.267371Z","iopub.status.idle":"2022-04-11T14:19:14.273332Z","shell.execute_reply.started":"2022-04-11T14:19:14.267336Z","shell.execute_reply":"2022-04-11T14:19:14.271930Z"},"trusted":true},"execution_count":87,"outputs":[]},{"cell_type":"code","source":"ohe.fit(train_copy[nominal_features])\n\nencoded = ohe.transform(train_copy[nominal_features]).toarray()\n\nfeature_names = ohe.get_feature_names(nominal_features)\n\ntrain_copy = pd.concat([train_copy.select_dtypes(exclude='object'), \n               pd.DataFrame(encoded,columns=feature_names).astype(int)], axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-04-11T14:20:38.651510Z","iopub.execute_input":"2022-04-11T14:20:38.652409Z","iopub.status.idle":"2022-04-11T14:20:38.685075Z","shell.execute_reply.started":"2022-04-11T14:20:38.652355Z","shell.execute_reply":"2022-04-11T14:20:38.683850Z"},"trusted":true},"execution_count":89,"outputs":[]},{"cell_type":"code","source":"train_copy.shape","metadata":{"execution":{"iopub.status.busy":"2022-04-11T14:20:49.230431Z","iopub.execute_input":"2022-04-11T14:20:49.231257Z","iopub.status.idle":"2022-04-11T14:20:49.236241Z","shell.execute_reply.started":"2022-04-11T14:20:49.231206Z","shell.execute_reply":"2022-04-11T14:20:49.235589Z"},"trusted":true},"execution_count":90,"outputs":[]},{"cell_type":"code","source":"encoded = ohe.transform(test_copy[nominal_features]).toarray()\n\n# feature_names = ohe.get_feature_names(nominal_features)\n\ntest_copy = pd.concat([test_copy.select_dtypes(exclude='object'), \n               pd.DataFrame(encoded,columns=feature_names).astype(int)], axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-04-11T14:20:53.050857Z","iopub.execute_input":"2022-04-11T14:20:53.051171Z","iopub.status.idle":"2022-04-11T14:20:53.083529Z","shell.execute_reply.started":"2022-04-11T14:20:53.051118Z","shell.execute_reply":"2022-04-11T14:20:53.082680Z"},"trusted":true},"execution_count":91,"outputs":[]},{"cell_type":"code","source":"test_copy.shape","metadata":{"execution":{"iopub.status.busy":"2022-04-11T14:20:54.250979Z","iopub.execute_input":"2022-04-11T14:20:54.251255Z","iopub.status.idle":"2022-04-11T14:20:54.256836Z","shell.execute_reply.started":"2022-04-11T14:20:54.251228Z","shell.execute_reply":"2022-04-11T14:20:54.255924Z"},"trusted":true},"execution_count":92,"outputs":[]},{"cell_type":"markdown","source":"# Use mathematical relations to create new features","metadata":{}},{"cell_type":"code","source":"fix, (both,both2,both3) = plt.subplots(1, 3, figsize = (12, 8))\n\nz = train_copy['SalePrice']\n\n\n\nh = ((train_copy['OverallCond']))\n\nv = ((train_copy['OverallQual'])) \n\ny = ((train_copy['OverallQual']))+ ((train_copy['OverallCond']))\n\nboth.scatter(h,z,color = 'red')\nboth2.scatter(v,z,color = 'blue')\nboth3.scatter(y,z,color = 'black')\n\n\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-11T14:22:58.941565Z","iopub.execute_input":"2022-04-11T14:22:58.941849Z","iopub.status.idle":"2022-04-11T14:22:59.423842Z","shell.execute_reply.started":"2022-04-11T14:22:58.941820Z","shell.execute_reply":"2022-04-11T14:22:59.423021Z"},"trusted":true},"execution_count":96,"outputs":[]},{"cell_type":"markdown","source":"no clear relation here,so it's better not to touch those features","metadata":{}},{"cell_type":"code","source":"fix, (both,both2,both3) = plt.subplots(1, 3, figsize = (12, 8))\n\nz = train_copy['SalePrice']\n\n\n\nh = ((train_copy['GarageQual']))\n\nv = ((train_copy['GarageCond']))  \n\nx = ((train_copy['GarageCond']))+((train_copy['GarageQual']))\n\n\nboth.scatter(h,z,color = 'green')\nboth2.scatter(v,z,color = 'black')\nboth3.scatter(x,z,color = 'red')\n\n\n\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-11T14:23:00.380853Z","iopub.execute_input":"2022-04-11T14:23:00.381176Z","iopub.status.idle":"2022-04-11T14:23:00.859849Z","shell.execute_reply.started":"2022-04-11T14:23:00.381128Z","shell.execute_reply":"2022-04-11T14:23:00.859126Z"},"trusted":true},"execution_count":97,"outputs":[]},{"cell_type":"code","source":"train_copy.insert(1, 'GarageCond/Qual',((train_copy['GarageCond']))+((train_copy['GarageQual'])))\ntrain_copy.drop(columns = ['GarageCond','GarageQual'],axis = 1,inplace = True)\n\ntest_copy.insert(1, 'GarageCond/Qual',((test_copy['GarageCond']))+((test_copy['GarageQual'])))\ntest_copy.drop(columns = ['GarageCond','GarageQual'],axis = 1,inplace = True)","metadata":{"execution":{"iopub.status.busy":"2022-04-11T14:23:00.861266Z","iopub.execute_input":"2022-04-11T14:23:00.861480Z","iopub.status.idle":"2022-04-11T14:23:00.880547Z","shell.execute_reply.started":"2022-04-11T14:23:00.861453Z","shell.execute_reply":"2022-04-11T14:23:00.879478Z"},"trusted":true},"execution_count":98,"outputs":[]},{"cell_type":"code","source":"score(train_copy,True)","metadata":{"execution":{"iopub.status.busy":"2022-04-11T14:23:03.340609Z","iopub.execute_input":"2022-04-11T14:23:03.341083Z","iopub.status.idle":"2022-04-11T14:23:09.013591Z","shell.execute_reply.started":"2022-04-11T14:23:03.340917Z","shell.execute_reply":"2022-04-11T14:23:09.012610Z"},"trusted":true},"execution_count":99,"outputs":[]},{"cell_type":"code","source":"fix, (both,both2,both3) = plt.subplots(1, 3, figsize = (12, 8))\n\nz = train_copy['SalePrice']\n\n\n\nh = ((train_copy['LotArea']))\n\nv = ((train_copy['GrLivArea']))  \n\nx = train_copy['GrLivArea'] / train_copy['LotArea']\n\n\nboth.scatter(h,z,color = 'green')\nboth2.scatter(v,z,color = 'black')\nboth3.scatter(x,z,color = 'red')\n\n\n\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-11T14:23:09.015320Z","iopub.execute_input":"2022-04-11T14:23:09.015821Z","iopub.status.idle":"2022-04-11T14:23:09.478345Z","shell.execute_reply.started":"2022-04-11T14:23:09.015774Z","shell.execute_reply":"2022-04-11T14:23:09.477529Z"},"trusted":true},"execution_count":100,"outputs":[]},{"cell_type":"code","source":"train_copy.insert(1, 'LivLotRatio',(train_copy['GrLivArea'] / train_copy['LotArea']))\ntest_copy.insert(1, 'LivLotRatio',(test_copy['GrLivArea'] / test_copy['LotArea']))\n\n\n","metadata":{"execution":{"iopub.status.busy":"2022-04-11T14:23:13.180714Z","iopub.execute_input":"2022-04-11T14:23:13.181369Z","iopub.status.idle":"2022-04-11T14:23:13.190390Z","shell.execute_reply.started":"2022-04-11T14:23:13.181318Z","shell.execute_reply":"2022-04-11T14:23:13.188949Z"},"trusted":true},"execution_count":101,"outputs":[]},{"cell_type":"code","source":"score(train_copy,True)","metadata":{"execution":{"iopub.status.busy":"2022-04-11T14:23:13.510443Z","iopub.execute_input":"2022-04-11T14:23:13.510724Z","iopub.status.idle":"2022-04-11T14:23:19.286776Z","shell.execute_reply.started":"2022-04-11T14:23:13.510696Z","shell.execute_reply":"2022-04-11T14:23:19.285831Z"},"trusted":true},"execution_count":102,"outputs":[]},{"cell_type":"code","source":"fix, (both,both2,both3) = plt.subplots(1, 3, figsize = (12, 8))\n\nz = train_copy['SalePrice']\n\n\n\nh = ((train_copy['2ndFlrSF']))\n\nv = ((train_copy['1stFlrSF']))  \n\nx = (train_copy['1stFlrSF']+train_copy['2ndFlrSF']) \n/ (train_copy['TotRmsAbvGrd']+train_copy['FullBath']+train_copy['HalfBath'])\n\n\nboth.scatter(h,z,color = 'green')\nboth2.scatter(v,z,color = 'black')\nboth3.scatter(x,z,color = 'red')\n\n\n\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-11T14:23:19.288433Z","iopub.execute_input":"2022-04-11T14:23:19.288801Z","iopub.status.idle":"2022-04-11T14:23:19.779682Z","shell.execute_reply.started":"2022-04-11T14:23:19.288771Z","shell.execute_reply":"2022-04-11T14:23:19.779035Z"},"trusted":true},"execution_count":103,"outputs":[]},{"cell_type":"code","source":"train_copy.insert(1, 'AreaRoomsRatio',((train_copy['1stFlrSF']+train_copy['2ndFlrSF']) \n/ (train_copy['TotRmsAbvGrd']+train_copy['FullBath']+train_copy['HalfBath'])))\n\n\ntest_copy.insert(1, 'AreaRoomsRatio',((test_copy['1stFlrSF']+test_copy['2ndFlrSF']) \n/ (test_copy['TotRmsAbvGrd']+test_copy['FullBath']+test_copy['HalfBath'])))\n","metadata":{"execution":{"iopub.status.busy":"2022-04-11T14:23:24.340864Z","iopub.execute_input":"2022-04-11T14:23:24.341210Z","iopub.status.idle":"2022-04-11T14:23:24.351464Z","shell.execute_reply.started":"2022-04-11T14:23:24.341173Z","shell.execute_reply":"2022-04-11T14:23:24.350543Z"},"trusted":true},"execution_count":104,"outputs":[]},{"cell_type":"code","source":"score(train_copy,True)","metadata":{"execution":{"iopub.status.busy":"2022-04-11T14:23:24.670873Z","iopub.execute_input":"2022-04-11T14:23:24.671189Z","iopub.status.idle":"2022-04-11T14:23:30.594867Z","shell.execute_reply.started":"2022-04-11T14:23:24.671131Z","shell.execute_reply":"2022-04-11T14:23:30.593949Z"},"trusted":true},"execution_count":105,"outputs":[]},{"cell_type":"markdown","source":"# K-means for feature creation","metadata":{}},{"cell_type":"code","source":"from sklearn.cluster import KMeans","metadata":{"execution":{"iopub.status.busy":"2022-04-11T14:23:33.660537Z","iopub.execute_input":"2022-04-11T14:23:33.660812Z","iopub.status.idle":"2022-04-11T14:23:33.732813Z","shell.execute_reply.started":"2022-04-11T14:23:33.660784Z","shell.execute_reply":"2022-04-11T14:23:33.732198Z"},"trusted":true},"execution_count":106,"outputs":[]},{"cell_type":"code","source":"def cluster_labels(df,features,n_clusters = 20):\n    \"\"\"\n    this function assigns cluster labels to each example\n    \n    \"\"\"\n    \n    # we scale(standarize) the data:\n    df_scaled = df.loc[:,features]\n    df_scaled = (df_scaled - df_scaled.mean(axis=0)) / df_scaled.std(axis=0)\n    \n    # create a k-means object and fit it\n    kmeans = KMeans(n_clusters=n_clusters, n_init=50, random_state=0)\n    df[\"Cluster\"] = kmeans.fit_predict(df_scaled)\n    \n    return df","metadata":{"execution":{"iopub.status.busy":"2022-04-11T14:23:33.820610Z","iopub.execute_input":"2022-04-11T14:23:33.821248Z","iopub.status.idle":"2022-04-11T14:23:33.826841Z","shell.execute_reply.started":"2022-04-11T14:23:33.821216Z","shell.execute_reply":"2022-04-11T14:23:33.826117Z"},"trusted":true},"execution_count":107,"outputs":[]},{"cell_type":"code","source":"Area_features = ['TotalBsmtSF','LotArea','GrLivArea','1stFlrSF','2ndFlrSF']\ntrain_copy = cluster_labels(train_copy,Area_features)\ntest_copy = cluster_labels(test_copy,Area_features)\n\n","metadata":{"execution":{"iopub.status.busy":"2022-04-11T14:23:34.020565Z","iopub.execute_input":"2022-04-11T14:23:34.021163Z","iopub.status.idle":"2022-04-11T14:23:36.489167Z","shell.execute_reply.started":"2022-04-11T14:23:34.021099Z","shell.execute_reply":"2022-04-11T14:23:36.488445Z"},"trusted":true},"execution_count":108,"outputs":[]},{"cell_type":"code","source":"train_copy.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-11T14:23:36.491242Z","iopub.execute_input":"2022-04-11T14:23:36.491872Z","iopub.status.idle":"2022-04-11T14:23:36.518167Z","shell.execute_reply.started":"2022-04-11T14:23:36.491827Z","shell.execute_reply":"2022-04-11T14:23:36.517240Z"},"trusted":true},"execution_count":109,"outputs":[]},{"cell_type":"code","source":"score(train_copy,True)","metadata":{"execution":{"iopub.status.busy":"2022-04-11T14:23:36.521935Z","iopub.execute_input":"2022-04-11T14:23:36.524329Z","iopub.status.idle":"2022-04-11T14:23:42.770944Z","shell.execute_reply.started":"2022-04-11T14:23:36.524279Z","shell.execute_reply":"2022-04-11T14:23:42.770205Z"},"trusted":true},"execution_count":110,"outputs":[]},{"cell_type":"code","source":"# now we create features for distance from each cluster:\n\ndef cluster_distance(df, features, n_clusters=20):\n    X = df.copy()\n    # standarize the data\n    X_scaled = X.loc[:, features]\n    X_scaled = (X_scaled - X_scaled.mean(axis=0)) / X_scaled.std(axis=0)\n    \n    # fit the k-means object\n    kmeans = KMeans(n_clusters=20, n_init=50, random_state=0)\n    \n    #Create the cluster-distance features using `fit_transform`\n    df_cd = kmeans.fit_transform(X_scaled)\n    \n    # Label features and join to dataset\n    df_cd = pd.DataFrame(\n        df_cd, columns=[f\"Centroid_{i}\" for i in range(df_cd.shape[1])]\n                        )\n    \n    df = df.join(df_cd)\n    return df","metadata":{"execution":{"iopub.status.busy":"2022-04-11T14:23:42.772554Z","iopub.execute_input":"2022-04-11T14:23:42.772747Z","iopub.status.idle":"2022-04-11T14:23:42.780520Z","shell.execute_reply.started":"2022-04-11T14:23:42.772722Z","shell.execute_reply":"2022-04-11T14:23:42.779319Z"},"trusted":true},"execution_count":111,"outputs":[]},{"cell_type":"code","source":"train_copy = cluster_distance(train_copy,Area_features)\ntest_copy = cluster_distance(test_copy,Area_features)\n\n","metadata":{"execution":{"iopub.status.busy":"2022-04-11T14:23:42.782162Z","iopub.execute_input":"2022-04-11T14:23:42.782513Z","iopub.status.idle":"2022-04-11T14:23:45.090298Z","shell.execute_reply.started":"2022-04-11T14:23:42.782473Z","shell.execute_reply":"2022-04-11T14:23:45.089462Z"},"trusted":true},"execution_count":112,"outputs":[]},{"cell_type":"code","source":"train_copy.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-11T14:23:45.094302Z","iopub.execute_input":"2022-04-11T14:23:45.095096Z","iopub.status.idle":"2022-04-11T14:23:45.130468Z","shell.execute_reply.started":"2022-04-11T14:23:45.095055Z","shell.execute_reply":"2022-04-11T14:23:45.128603Z"},"trusted":true},"execution_count":113,"outputs":[]},{"cell_type":"code","source":"score(train_copy,True)","metadata":{"execution":{"iopub.status.busy":"2022-04-11T14:23:45.131872Z","iopub.execute_input":"2022-04-11T14:23:45.132859Z","iopub.status.idle":"2022-04-11T14:23:54.779866Z","shell.execute_reply.started":"2022-04-11T14:23:45.132811Z","shell.execute_reply":"2022-04-11T14:23:54.778941Z"},"trusted":true},"execution_count":114,"outputs":[]},{"cell_type":"markdown","source":"# Regression Models Development","metadata":{}},{"cell_type":"code","source":"# import the necessary modules\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.model_selection import cross_val_score, cross_val_predict\nfrom sklearn import metrics\n","metadata":{"execution":{"iopub.status.busy":"2022-04-11T14:24:52.421660Z","iopub.execute_input":"2022-04-11T14:24:52.421934Z","iopub.status.idle":"2022-04-11T14:24:52.430774Z","shell.execute_reply.started":"2022-04-11T14:24:52.421907Z","shell.execute_reply":"2022-04-11T14:24:52.429543Z"},"trusted":true},"execution_count":115,"outputs":[]},{"cell_type":"markdown","source":"### Use Extreme Gradient Boosting (XGBoost)","metadata":{}},{"cell_type":"code","source":"# create a standard scaler object\nscaler = StandardScaler()\n\n# create an ensemble regressor model object\nXGBRmodel =XGBRegressor()\n\n\nX = train_copy.drop(columns = [\"SalePrice\"])\nY = train_copy.SalePrice\n\n# create a pipeline \nXGBRpipe = make_pipeline(scaler, XGBRmodel) # standarizes the data and fit the model with it\n\nscore = cross_val_score(XGBRpipe, X, Y, cv=5,scoring=\"neg_mean_squared_error\")\n\nscore = -1 * score.mean()\nscore = np.sqrt(score)\n\nprint(\"avg score is : \",score)\n\n","metadata":{"execution":{"iopub.status.busy":"2022-04-11T14:25:01.221399Z","iopub.execute_input":"2022-04-11T14:25:01.221725Z","iopub.status.idle":"2022-04-11T14:25:10.783857Z","shell.execute_reply.started":"2022-04-11T14:25:01.221694Z","shell.execute_reply":"2022-04-11T14:25:10.782919Z"},"trusted":true},"execution_count":116,"outputs":[]},{"cell_type":"code","source":"# predictions = cross_val_predict(model, X_validation, Y_validation, cv=5)\n\npredictions = cross_val_predict(XGBRpipe, X, Y, cv=5)","metadata":{"execution":{"iopub.status.busy":"2022-04-11T14:25:16.651262Z","iopub.execute_input":"2022-04-11T14:25:16.652068Z","iopub.status.idle":"2022-04-11T14:25:26.268683Z","shell.execute_reply.started":"2022-04-11T14:25:16.652016Z","shell.execute_reply":"2022-04-11T14:25:26.267941Z"},"trusted":true},"execution_count":117,"outputs":[]},{"cell_type":"code","source":"accuracy = metrics.r2_score(Y, predictions)\nprint ('Cross-Predicted Accuracy:', accuracy)\n\n# quiet a good score","metadata":{"execution":{"iopub.status.busy":"2022-04-11T14:25:26.270516Z","iopub.execute_input":"2022-04-11T14:25:26.271063Z","iopub.status.idle":"2022-04-11T14:25:26.281459Z","shell.execute_reply.started":"2022-04-11T14:25:26.271012Z","shell.execute_reply":"2022-04-11T14:25:26.280089Z"},"trusted":true},"execution_count":118,"outputs":[]},{"cell_type":"code","source":"plt.scatter(Y, predictions)","metadata":{"execution":{"iopub.status.busy":"2022-04-11T14:25:26.282917Z","iopub.execute_input":"2022-04-11T14:25:26.284759Z","iopub.status.idle":"2022-04-11T14:25:26.537698Z","shell.execute_reply.started":"2022-04-11T14:25:26.284702Z","shell.execute_reply":"2022-04-11T14:25:26.536787Z"},"trusted":true},"execution_count":119,"outputs":[]},{"cell_type":"markdown","source":"# Hyperparameter tunning with GridSearch","metadata":{}},{"cell_type":"markdown","source":"This section takes time to excute, but it selects the optimal values for every model's parameters","metadata":{}},{"cell_type":"code","source":"# from sklearn.model_selection import GridSearchCV\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # first we create a hold out set\n\n# X = train_copy.drop(columns = [\"SalePrice\"])\n# Y = train_copy.SalePrice\n\n# x_train,x_validation,y_train,y_validation = train_test_split(X,Y,test_size = .3, random_state = 0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # now we build a number of models, create a list ofthe hyperparameters and initialize a grid search object\n\n# xgboost = XGBRegressor()\n# parameters = { 'learning_rate' :[0.001,0.01,0.1,0.5,1],\n#                'n_estimators'  :[100,200,500,700,1000],\n#                'subsample'     :[0.7,1],\n#                'max_depth'     :[3,4,5],\n#                'alpha'         :[0.9,1,1.1]}\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # fit the model with the data and use the grid search object to loop through the parameters to choose the best scoring parameters\n\n# clf = GridSearchCV(xgboost, parameters, cv = 5)\n# clf.fit(x_train, y_train)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # print the best scoring parameters\n# print(\"tuned hpyerparameters :(best parameters) \",clf.best_params_)\n# print(\"accuracy :\",clf.best_score_)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# the best parameters are :\n\n# (n_estimators=3000, learning_rate=0.05, max_depth=4, max_features='sqrt', min_samples_leaf=15, min_samples_split=10, loss='huber', random_state =42)                             ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # create a standard scaler object\n# scaler = StandardScaler()\n\n# # create an ensemble regressor model object\n# XGBRmodel =XGBRegressor(n_estimators=3000, learning_rate=0.05, max_depth=4, max_features='sqrt', min_samples_leaf=15, min_samples_split=10, loss='huber', random_state =42)                             \n\n\n# X = train_copy.drop(columns = [\"SalePrice\"])\n# Y = train_copy.SalePrice\n\n# # create a pipeline \n# XGBRpipe = make_pipeline(scaler, XGBRmodel) # standarizes the data and fit the model with it\n\n# score = cross_val_score(XGBRpipe, X, Y, cv=5,scoring=\"neg_mean_squared_error\")\n\n# score = -1 * score.mean()\n# score = np.sqrt(score)\n\n# print(\"avg score is : \",score)\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # predictions = cross_val_predict(model, X_validation, Y_validation, cv=5)\n\n# predictions = cross_val_predict(XGBRpipe, X, Y, cv=5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# accuracy = metrics.r2_score(Y, predictions)\n# print ('Cross-Predicted Accuracy:', accuracy)\n\n# # quiet a good score","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plt.scatter(Y, predictions)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Making predictions","metadata":{}},{"cell_type":"code","source":"# fit the standard scaler object with the training dataset\n\nscaler = StandardScaler()\n\nX = train_copy.drop(columns = [\"SalePrice\"])\nY = train_copy.SalePrice\n\nX = scaler.fit_transform(X)\n","metadata":{"execution":{"iopub.status.busy":"2022-04-11T14:31:59.861795Z","iopub.execute_input":"2022-04-11T14:31:59.862089Z","iopub.status.idle":"2022-04-11T14:31:59.868718Z","shell.execute_reply.started":"2022-04-11T14:31:59.862058Z","shell.execute_reply":"2022-04-11T14:31:59.868007Z"},"trusted":true},"execution_count":125,"outputs":[]},{"cell_type":"code","source":"# Build the XGBRegressor and fit it with the training dataset\n\nXGBRmodel =XGBRegressor(n_estimators=3000, learning_rate=0.05, max_depth=4, max_features='sqrt', min_samples_leaf=15, min_samples_split=10, loss='huber', random_state =42)                             \nXGBRmodel = XGBRmodel.fit(X,Y)","metadata":{"execution":{"iopub.status.busy":"2022-04-11T14:32:08.241558Z","iopub.execute_input":"2022-04-11T14:32:08.241820Z","iopub.status.idle":"2022-04-11T14:32:22.228404Z","shell.execute_reply.started":"2022-04-11T14:32:08.241793Z","shell.execute_reply":"2022-04-11T14:32:22.227350Z"},"trusted":true},"execution_count":127,"outputs":[]},{"cell_type":"code","source":"# transform the test data with the standard scaler object\n\ntest_copy= scaler.transform(test_copy)\n","metadata":{"execution":{"iopub.status.busy":"2022-04-11T14:32:22.230216Z","iopub.execute_input":"2022-04-11T14:32:22.230446Z","iopub.status.idle":"2022-04-11T14:32:22.243271Z","shell.execute_reply.started":"2022-04-11T14:32:22.230419Z","shell.execute_reply":"2022-04-11T14:32:22.242469Z"},"trusted":true},"execution_count":128,"outputs":[]},{"cell_type":"code","source":"# make predictions\n\npredictions = XGBRmodel.predict(test_copy)","metadata":{"execution":{"iopub.status.busy":"2022-04-11T14:32:22.244392Z","iopub.execute_input":"2022-04-11T14:32:22.244763Z","iopub.status.idle":"2022-04-11T14:32:22.353153Z","shell.execute_reply.started":"2022-04-11T14:32:22.244720Z","shell.execute_reply":"2022-04-11T14:32:22.352105Z"},"trusted":true},"execution_count":129,"outputs":[]},{"cell_type":"code","source":"# log transformation is applied to the preddictions, so don't forget to transform them back\n# You can use numpy.expm1() which is the inverse of numpy.log1p()\n\npredictions = np.expm1(predictions)\n","metadata":{"execution":{"iopub.status.busy":"2022-04-11T14:42:23.102541Z","iopub.execute_input":"2022-04-11T14:42:23.102817Z","iopub.status.idle":"2022-04-11T14:42:23.107287Z","shell.execute_reply.started":"2022-04-11T14:42:23.102789Z","shell.execute_reply":"2022-04-11T14:42:23.106404Z"},"trusted":true},"execution_count":140,"outputs":[]},{"cell_type":"code","source":"plt.hist(predictions)","metadata":{"execution":{"iopub.status.busy":"2022-04-11T14:47:40.571399Z","iopub.execute_input":"2022-04-11T14:47:40.571672Z","iopub.status.idle":"2022-04-11T14:47:40.800203Z","shell.execute_reply.started":"2022-04-11T14:47:40.571646Z","shell.execute_reply":"2022-04-11T14:47:40.799215Z"},"trusted":true},"execution_count":146,"outputs":[]},{"cell_type":"markdown","source":"# Generate Submission File","metadata":{}},{"cell_type":"code","source":"\nAmesSubmission = pd.DataFrame({ 'Id': original_test.Id,\n                            'SalePrice': predictions })\nAmesSubmission.to_csv(\"AmesSubmission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2022-04-11T15:00:10.991511Z","iopub.execute_input":"2022-04-11T15:00:10.991808Z","iopub.status.idle":"2022-04-11T15:00:11.005118Z","shell.execute_reply.started":"2022-04-11T15:00:10.991777Z","shell.execute_reply":"2022-04-11T15:00:11.004288Z"},"trusted":true},"execution_count":161,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}